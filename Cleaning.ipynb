{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import html2text\n",
    "# from sqlalchemy import create_engine\n",
    "from langdetect import detect\n",
    "import dateparser\n",
    "from news_cleaning_config import alias, strip_patterns, pub_type_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_filepath = 'data/summer.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading file for the first time\n",
    "\n",
    "news = pd.read_csv(news_filepath, sep=',', quotechar='\"', escapechar=\"\\\\\")\n",
    "news = news.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oksana/Dev/TextClassification/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 477259 entries, 31443 to 33302\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   title         477254 non-null  object \n",
      " 1   text          477222 non-null  object \n",
      " 2   subtitle      245392 non-null  object \n",
      " 3   link          477259 non-null  object \n",
      " 4   domain        477259 non-null  object \n",
      " 5   datetime      477259 non-null  object \n",
      " 6   views         197102 non-null  float64\n",
      " 7   created_at    477259 non-null  object \n",
      " 8   category      377096 non-null  object \n",
      " 9   language      477259 non-null  object \n",
      " 10  pub_type      477259 non-null  object \n",
      " 11  author        329206 non-null  object \n",
      " 12  tags          387336 non-null  object \n",
      " 13  source        59893 non-null   object \n",
      " 14  author_title  27698 non-null   object \n",
      " 15  domain_alias  477259 non-null  object \n",
      "dtypes: float64(1), object(15)\n",
      "memory usage: 61.9+ MB\n"
     ]
    }
   ],
   "source": [
    "news = pd.read_csv(news_filepath, index_col=0)\n",
    "news['datetime'] = pd.to_datetime(news.datetime, utc=True).dt.tz_convert('Europe/Kiev')\n",
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['domain_alias'] = news.domain.apply(lambda x: alias[x])\n",
    "news = news.drop_duplicates('link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update espreso dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news['datetime'] = pd.to_datetime(news.datetime, utc=True).dt.tz_convert('Europe/Kiev')\n",
    "date_string = news[news.domain=='espreso.tv'].text.str.extract(r'(^\\d{1,2} \\w+, 20\\d{2}, \\d{2}\\:\\d{2})').squeeze()\n",
    "tmstmp = date_string.apply(lambda x: dateparser.parse(x, date_formats=['%d %B, %Y, %H:%M'], languages=['uk']))\n",
    "tmstmp = tmstmp.dt.tz_localize('Europe/Kiev')\n",
    "news.datetime = news.datetime.mask(news.domain=='espreso.tv', tmstmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from database (old option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(user='postgres', password='pgpass', db_name='media_ecosystem', table_name='december', chunksize=5000):\n",
    "    db_url = 'postgresql://localhost/{}?user={}&password={}'.format(db_name, user, password)\n",
    "    sql_engine = create_engine(db_url, echo=False)\n",
    "    conn = sql_engine.connect()\n",
    "    if chunksize:\n",
    "        return pd.read_sql_table(table_name, conn, chunksize=chunksize)  \n",
    "    else:\n",
    "        return pd.read_sql_table(table_name, conn)  \n",
    "\n",
    "    \n",
    "def get_news(table_chunks, news_file):\n",
    "    k=0\n",
    "    df_parts = []\n",
    "    text_maker = get_text_maker()\n",
    "    for chunk in table_chunks:\n",
    "        chunk['datetime'] = pd.to_datetime(chunk.datetime, utc=True).dt.tz_convert('Europe/Kiev')\n",
    "#         chunk = chunk[chunk.datetime.dt.month>8]\n",
    "#         chunk = chunk[chunk.domain==\"suspilne.media\"]\n",
    "        if not chunk.empty:\n",
    "            chunk['text'] = chunk.text.apply(lambda x: text_maker.handle(x) if pd.notnull(x) else None)\n",
    "            df_parts.append(chunk)\n",
    "        del chunk\n",
    "        print(k)\n",
    "        k += 1\n",
    "    df = pd.concat(df_parts)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(news_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicates by link (same articles but in different languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop_duplicates('link')\n",
    "\n",
    "focus_link_pattern = ('https://focus.ua/(?:uk/)?[\\w\\-]+/(\\d+)\\-.*', '/uk/')\n",
    "censor_link_pattern = ('https://censor.net/(?:ua|ru)/\\w+/(\\d+)/.*', '/ua/')\n",
    "\n",
    "def remove_duplicates(df, link_pattern_tuple):\n",
    "    df['article_id'] = df.link.str.extract(link_pattern_tuple[0], expand=False)\n",
    "    duplicates = df.duplicated('article_id', keep=False) & df.article_id.notna()\n",
    "    df = df[(~duplicates)|df.link.str.contains(link_pattern_tuple[1])]\n",
    "    df = df.drop(columns=['article_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494687, 16)\n",
      "(477310, 16)\n"
     ]
    }
   ],
   "source": [
    "print(news.shape)\n",
    "news = remove_duplicates(news, focus_link_pattern)\n",
    "news = remove_duplicates(news, censor_link_pattern)\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_html(text):\n",
    "    text_maker = html2text.HTML2Text()\n",
    "    text_maker.ignore_links = True\n",
    "    text_maker.ignore_images = True\n",
    "    text_maker.unicode_snob = True\n",
    "    text_maker.body_width = 0\n",
    "    text_maker.single_line_break = True\n",
    "    text_maker.ignore_emphasis = True\n",
    "    return text_maker.handle(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 52s, sys: 13.1 s, total: 14min 5s\n",
      "Wall time: 14min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "part = news.iloc[200000:].text.apply(get_text_from_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'text', 'subtitle', 'link', 'domain', 'datetime',\n",
       "       'views', 'created_at', 'category', 'language', 'pub_type', 'author',\n",
       "       'tags', 'source', 'author_title', 'domain_alias'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.text.update(part)\n",
    "del part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv(news_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up wrong characters, newlines and latin/cyrillic character mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_to_cyr_map = {\n",
    "    'a': 'а',\n",
    "    'c': 'с',\n",
    "    'e': 'е',\n",
    "    'i': 'і',\n",
    "    'l': 'І',\n",
    "    'o': 'о',\n",
    "    'u': 'и',\n",
    "    'p': 'р',\n",
    "    'n': 'п',\n",
    "    'm': 'т',\n",
    "    'x': 'х',\n",
    "    'y': 'у',\n",
    "    'k': 'к',\n",
    "    'b': 'ь',\n",
    "    'r': 'г',\n",
    "    'A': 'А',\n",
    "    'B': 'В',\n",
    "    'C': 'С',\n",
    "    'E': 'Е',\n",
    "    'H': 'Н',\n",
    "    'I': 'І',\n",
    "    'K': 'К',\n",
    "    'M': 'М',\n",
    "    'O': 'О',\n",
    "    'P': 'Р',\n",
    "    'T': 'Т',\n",
    "    'X': 'Х',\n",
    "    'Y': 'У',\n",
    "    \"á\": \"а́\",\n",
    "    \"Á\": \"А́\",\n",
    "    \"é\": \"е́\",\n",
    "    \"É\": \"Е́\",\n",
    "    \"í\": \"і́\",\n",
    "    \"Í\": \"І́\",\n",
    "    \"ḯ\": \"ї́\",\n",
    "    \"Ḯ\": \"Ї́\",\n",
    "    \"ó\": \"о́\",\n",
    "    \"Ó\": \"О́\",\n",
    "    \"ú\": \"и́\",\n",
    "    \"ý\": \"у́\",\n",
    "    \"Ý\": \"У́\",\n",
    "    \"0\": \"о\"\n",
    "}\n",
    "\n",
    "cyr_to_lat_map = {}\n",
    "for k, v in lat_to_cyr_map.items():\n",
    "    cyr_to_lat_map[v] = k\n",
    "\n",
    "APOSTROPHY_LIKE = ('”',\n",
    "                   '‟',\n",
    "                   '\"',\n",
    "                   '‘',\n",
    "                   '′',\n",
    "                   '\\u0313',\n",
    "                   '΄',\n",
    "                   '’',\n",
    "                   '´',\n",
    "                   '`',\n",
    "                   '’',\n",
    "                   '?',\n",
    "                   '*',\n",
    "                   )\n",
    "APOSTROPHY_PREFIX = 'бвгґдзкмнпрстфхш'\n",
    "APOSTROPHY_SUFFIX = 'єїюя'\n",
    "\n",
    "\n",
    "def remove_part_from_text(title, text):\n",
    "    if pd.notnull(title) and pd.notnull(text):\n",
    "        try:\n",
    "            title = re.escape(title)\n",
    "            text = re.sub(title, '', text)\n",
    "        except:\n",
    "            print(title)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_newlines(text):\n",
    "    if pd.notna(text):\n",
    "        text = re.sub(r\"\\n \\n\", \"\\n\", text)\n",
    "        text = re.sub(r\"\\r\\.?\", \" \", text)\n",
    "        text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "        text = re.sub(r\" {2,}\", \" \", text)\n",
    "        text = text.strip()\n",
    "    return text\n",
    "    \n",
    "    \n",
    "def clean(text):\n",
    "    if pd.notnull(text):\n",
    "        text = unicodedata.normalize(\"NFKC\", text)\n",
    "        text = re.sub(r\"\\\\n\", \"\\n\", text)\n",
    "        text = remove_newlines(text)\n",
    "\n",
    "        # change strange apostrophe to '\n",
    "        text = re.sub(r\"([{prefix}])[{apostrophy}]([{suffix}])\".format(\n",
    "            prefix=APOSTROPHY_PREFIX, apostrophy=''.join(APOSTROPHY_LIKE), suffix=APOSTROPHY_SUFFIX),\n",
    "            r\"\\1'\\2\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"([{prefix}])&#39\\s?([{suffix}])\".format(\n",
    "            prefix=APOSTROPHY_PREFIX, suffix=APOSTROPHY_SUFFIX), r\"\\1'\\2\", text)\n",
    "\n",
    "        # add space between sentences if needed (with workaround for Цензор.НЕТ and ZN.UA)\n",
    "        text = re.sub(r\"([\\.\\?\\!])(?!(NET|UA|НЕТ))([А-ЯІЇЄҐA-Z])\", r\"\\1 \\2\\3\", text)\n",
    "       \n",
    "        # clean up latin/cyrillic character mix\n",
    "        # cases:\n",
    "        # - latin symbols that look like cyrillic in ukrainian words\n",
    "        # - cyrillic symbols that look like latin in english words\n",
    "        text = re.sub(\n",
    "            r\"([бвгґдєжзийклмнптфцчшщьюяБГҐДЄЖЗИЙЛПФХЦЧШЩЬЮЯ]['’ʼ]?)([aceiopxyunmkbr0ABCEHIKMOPTXYáÁéÉíÍḯḮóÓúýÝ])\",\n",
    "            lambda x: x.group(1) + lat_to_cyr_map[x.group(2)], text)\n",
    "\n",
    "        text = re.sub(\n",
    "            r\"([aceiopxyaceiopxyunmkbr0ABCEHIKMOPTXYáÁéÉíÍḯḮóÓúýÝ])(['’ʼ]?[бвгґдєжзийклмнптфцчшщьюяБГҐДЄЖЗИЙЛПФХЦЧШЩЬЮЯ])\",\n",
    "            lambda x: lat_to_cyr_map[x.group(1)] + x.group(2), text)\n",
    "\n",
    "        text = re.sub(r\"([bdfghjklmnrstuvwzDFGJLNQRSUVWZ]['’ʼ]?)([асеіорхуАВСЕНІКМНОРТХУ])\",\n",
    "                      lambda x: x.group(1) + cyr_to_lat_map[x.group(2)], text)\n",
    "\n",
    "        text = re.sub(r\"([асеіорхуАВСЕНІКМНОРТХУ])(['’ʼ]?[bdfghjklmnrstuvwzDFGJLNQRSUVWZ])\",\n",
    "                      lambda x: cyr_to_lat_map[x.group(1)] + x.group(2), text)\n",
    "\n",
    "        text = re.sub(r\"([а-яіїєґА-ЯІЇЄҐ]['’ʼ]?)([aceiopxyunmkbr0ABCEHIKMHOPTXYáÁéÉíÍḯḮóÓúýÝ])(['’ʼ]?[а-яіїєґА-ЯІЇЄҐ])\",\n",
    "                      lambda x: x.group(1) + lat_to_cyr_map[x.group(2)] + x.group(3), text)\n",
    "\n",
    "        text = re.sub(r\"([a-zA-Z]['’ʼ]?)([асеіорхуАВСЕНІКМНОРТХУ])(['’ʼ]?[a-zA-Z])\",\n",
    "                      lambda x: x.group(1) + cyr_to_lat_map[x.group(2)] + x.group(3), text)\n",
    "\n",
    "        text = re.sub(r\"([а-яіїєґ]\\W{0,2} )([ayico])( [А-ЯІЇЄҐа-яіїєґ])\",\n",
    "                      lambda x: x.group(1) + lat_to_cyr_map[x.group(2)] + x.group(3), text)\n",
    "\n",
    "        text = re.sub(r\"([AIYBKOl])( [А-ЯІЇЄҐа-яіїєґ])\",\n",
    "                      lambda x: lat_to_cyr_map[x.group(1)] + x.group(2), text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_cleaning(df):\n",
    "    df['text'] = df.text.apply(clean)\n",
    "    df['title'] = df.title.apply(clean)\n",
    "    df['subtitle'] = df.subtitle.apply(clean)\n",
    "    df['title'] = df.title.str.replace(r'\\n', ' ')\n",
    "    df['subtitle'] = df.subtitle.str.replace(r'\\n', ' ')\n",
    "    df.title.update(df[df.domain=='https://www.rbc.ua'].title.str.replace(r'^\\d+\\:\\d+', ''))\n",
    "    df['text'] = df.apply(lambda row: remove_part_from_text(row.title, row.text), axis=1)\n",
    "    df['text'] = df.apply(lambda row: remove_part_from_text(row.subtitle, row.text), axis=1)\n",
    "    return df\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oksana/Dev/TextClassification/venv/lib/python3.7/site-packages/ipykernel_launcher.py:141: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/Users/oksana/Dev/TextClassification/venv/lib/python3.7/site-packages/ipykernel_launcher.py:142: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/Users/oksana/Dev/TextClassification/venv/lib/python3.7/site-packages/ipykernel_launcher.py:143: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "news = text_cleaning(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pring some news samples to see redundant text patterns (or save some sample to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in news.domain.unique():\n",
    "    print(d, '\\n')\n",
    "    p = news[news.domain==d].sample(1)\n",
    "    print('title:', p.title.iloc[0])\n",
    "    print('subtitle:', p.subtitle.iloc[0])\n",
    "    print('text:', p.text.iloc[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(news, domains = [], sample_size = 40, month=0, lang = '', output_file = '../data/new_samples.csv'):\n",
    "    news_samples = []\n",
    "    lang_mask = news.lang==lang if lang else True\n",
    "    period_mask = news.datetime.dt.month==month\n",
    "    for d in domains:\n",
    "        try:\n",
    "            news_samples.append(news[(news.domain==d)&period_mask&lang_mask].sample(sample_size))\n",
    "        except:\n",
    "            pass\n",
    "    news_samples = pd.concat(news_samples)\n",
    "    news_samples.to_csv(output_file, index=False)\n",
    "    return news_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip redundant text from news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystrip(df):\n",
    "    for domain, patterns in strip_patterns.items():\n",
    "        print(domain)\n",
    "        domain_mask = df.domain.str.contains(domain)\n",
    "        for part_to_strip in patterns:\n",
    "            df.text.update(df[domain_mask].text.str.replace(part_to_strip[0], \"\", flags=part_to_strip[1]))\n",
    "    df['text'] = df.text.apply(remove_newlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oksana/Dev/TextClassification/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apostrophe.ua\n",
      "https://www.rbc.ua\n",
      "https://www.unian.ua\n",
      "ukrinform.ua\n",
      "https://censor.net.ua\n",
      "www.unn.com.ua\n",
      "https://politeka.net/uk\n",
      "www.radiosvoboda.org\n",
      "https://dt.ua/\n",
      "https://hromadske.ua/\n",
      "https://www.obozrevatel.com\n",
      "https://www.segodnya.ua/ua\n",
      "focus.ua\n",
      "112.ua\n",
      "https://www.liga.net\n",
      "espreso.tv\n",
      "strana.ua\n",
      "tsn.ua\n",
      "https://hromadske.radio\n",
      "znaj.ua\n",
      "fakty.com.ua\n",
      "https://www.epravda.com.ua\n",
      "https://www.pravda.com.ua\n",
      "https://ukr.lb.ua\n",
      "https://ukranews.com\n",
      "zik.ua\n",
      "https://ua.korrespondent.net/\n",
      "vgolos.com.ua\n",
      "glavcom.ua\n",
      "24tv.ua\n",
      "nv.ua\n",
      "suspilne.media\n",
      "babel.ua\n",
      "bykvu.com\n",
      "golos.ua\n",
      "vesti.ua\n",
      "fakty.ua\n",
      "zaxid.net\n",
      "kp.ua\n",
      "telegraf.com.ua\n",
      "today.ua\n",
      "gordonua.com\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "mystrip(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set language based on characters counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ru = ['https://ukranews.com', 'focus.ua', 'strana.ua', \\\n",
    "#       'https://censor.net.ua', 'nv.ua', 'telegraf.com.ua', \\\n",
    "#       'vesti.ua', 'golos.ua', 'kp.ua']\n",
    "\n",
    "ru = ['https://ukranews.com', 'strana.ua', \\\n",
    "      'nv.ua', 'telegraf.com.ua', \\\n",
    "      'vesti.ua', 'golos.ua', 'kp.ua']\n",
    "\n",
    "def set_language(news):\n",
    "    news.language.mask(news.text.str.contains(r\"[іїІЇЄҐґє]\", na=False), 'uk', inplace=True)\n",
    "    news.language.mask(news.domain.str.match(r\"|\".join(ru)), 'ru', inplace=True)\n",
    "    news.language.mask(news.text.str.contains(r\"([ЫыЁёЭэЪъ].*){5,}\", flags=re.S, na=False), 'ru', inplace=True)\n",
    "    news.language.mask(news.text.str.contains(r\"([іїІЇЄҐґє].*){10,}\", flags=re.S, na=False), 'uk', inplace=True)\n",
    "    \n",
    "    news.language.mask(((news.domain=='https://www.liga.net')&(news.language.isna())), 'ru', inplace=True)\n",
    "    \n",
    "    news.language.mask((news.language.isna())&(news.text.str.contains(r\"([іїІЇЄҐґє].*){3,}\", flags=re.S, na=False)), 'uk', inplace=True)\n",
    "    news.language.mask((news.language.isna())&(news.text.str.contains(r\"([ЫыЁёЭэЪъ].*){3,}\", flags=re.S, na=False)), 'ru', inplace=True)\n",
    "    \n",
    "    news.language.mask((news.language.isna())&(news.title.str.contains(r\"([іїІЇЄҐґє].*){1,}\", flags=re.S, na=False)), 'uk', inplace=True)\n",
    "    news.language.mask((news.language.isna())&(news.title.str.contains(r\"([ЫыЁёЭэЪъ].*){1,}\", flags=re.S, na=False)), 'ru', inplace=True)\n",
    "    \n",
    "    for i, r in news[news.language.isna()&news.text.notna()].iterrows():\n",
    "        try:\n",
    "            if detect(r.text)=='en':\n",
    "                news.language.at[i] = 'en'\n",
    "        except:\n",
    "            pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oksana/Dev/TextClassification/venv/lib/python3.7/site-packages/pandas/core/strings/accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "set_language(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check news where language is None and set the language by hand or delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[news.language.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Some sample patterns'''\n",
    "\n",
    "# news = news[news.title!='тест']\n",
    "# news.loc[news.language.isna()&(news.domain!='www.unn.com.ua'), 'language'] = 'ru'\n",
    "# news.loc[news.language.isna()&(news.domain=='112.ua'), 'language'] = 'uk'\n",
    "# news = news[news.language.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set publication type based on category, tags or text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_type(df, pub_type_patterns):\n",
    "    for key, values in pub_type_patterns.items():\n",
    "        target_column = key.split('_')[1]\n",
    "        for domain, patterns in values.items():\n",
    "            for pat in patterns:\n",
    "                df.pub_type.mask(df[target_column].str.contains(pat[0], flags=re.I, na=False), pat[1], inplace=True)\n",
    "                \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = get_publication_type(news, get_publication_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news           459073\n",
       "publication     10804\n",
       "blog             7433\n",
       "Name: pub_type, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.pub_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'text', 'subtitle', 'link', 'domain', 'datetime', 'views',\n",
       "       'created_at', 'category', 'language', 'pub_type', 'author', 'tags',\n",
       "       'source', 'author_title', 'domain_alias'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.to_csv(news_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
